# @package _global_

horizon: 4

## Config for the temperature guided model specifically on the MuJoCo environment
dataset:
  max_episode_length: 1000
  terminal_penalty: -100
  discount: 0.997 
  padding_terminations: zero # In DV no padding is applied. We still pad since we do not use seperate
  padding_truncations:       # dataloaders for the bellman value update (where we need termination signals).
  repeat_rewards_at_terminations: False

renderer:
  _target_: tgdp.rendering.MuJoCoLocomotionRenderer
  env_name: ${env}
  # Render Kwargs
  trackbodyid: 2
  distance: 10
  lookat: [5, 2, 0.5]
  elevation: 0

diffusion_model:
  network:
  reweight_samples: True # DV in fact does some reweighting of the samples in a batch
  reweight_factor: 2
  reweight_bias: 1
  reweight_key: mc_return

guides:
  mc_return: # Used for sample reweighting during training
    _target_: tgdp.models.guidance.MonteCarloReturnGuide
    network:
    loss_fn:
    train_noise_conditional_network: False
  bellman_value: # Used for plan selection during inference
    _target_: tgdp.models.guidance.BellmanValueGuide
    network:
      _target_: tgdp.networks.ema_wrapper.EMANetworkWrapper
      wrapped_network:
        _target_: tgdp.networks.guides.GuideMLPNet
        input_size: ${observation_dim}
        sigma_embedding:
        condition_embedding:
        input_embedding:
        fully_connected_sizes: [256,256]
        norm_type: layer
        use_dropout: False
    train_noise_conditional_network: False
    loss_fn:
      _target_: tgdp.models.losses.ValueL2

planner:
  ensemble_num_samples: 50
  ensemble_value_key: bellman_value