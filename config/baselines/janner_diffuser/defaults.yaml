# @package _global_

## Default config for the Janner Diffuser model 

horizon: 32

dataset:
  _target_: tgdp.datasets.D4RLDataset
  env_name: ${env}
  normalizers:
    observations: 
      _target_: tgdp.datasets.normalizers.GaussianNormalizer
    actions:
      _target_: tgdp.datasets.normalizers.GaussianNormalizer
  datastore:
    _target_: tgdp.datasets.datastore.NumpyDatastore
    _partial_: True
  max_n_episodes: 100000
  max_episode_length: 1000
  terminal_penalty: -100
  compute_mc_return: True
  discount: 0.997 # Paper and checkpoint uses 0.997, Repo uses 0.99
  horizon: ${horizon}
  padding_terminations: zero
  padding_truncations: zero

renderer:
  _target_: tgdp.rendering.MuJoCoLocomotionRenderer
  env_name: ${env}
  # Render Kwargs
  trackbodyid: 2
  distance: 10
  lookat: [5, 2, 0.5]
  elevation: 0

diffusion_model:
    _target_: tgdp.models.diffusion.ClassifierGuidedDiffusion
    network: 
      _target_: tgdp.networks.ema_wrapper.EMANetworkWrapper
      wrapped_network:
        _target_: tgdp.networks.diffusion.TemporalUNetFilm
        input_size: ${add:${observation_dim},${action_dim}}
        sigma_embedding:
          _target_: tgdp.networks.embeddings.SinusoidalEmbedding
          embedding_size: 32
          hidden_size_factor: 4
        local_condition_size:
        down_sizes: [32, 64, 128, 256] 
        kernel_size: 5
        n_groups: 8
        predict_scale_of_condition: False
    guides: ${guides}
    guide_scales: 
      trajectory_return: ???
    n_guide_steps: 2
    scale_grad_by_var: True
    sigma_stop_grad: ???
    scaling:
      _target_: tgdp.models.scaling.IDDPMAbsoluteScaling
      M: 20
    loss_fn:
      _target_: tgdp.models.losses.WeightedDiffusionL2
      action_dim: ${action_dim}
      observation_dim: ${observation_dim}
      horizon: ${horizon}
      weight_config:
        first_action_weight: 10.
        weight_discount: 1.
    conditioned_loss: True
    mask_conditioned_loss: True

guides:
  trajectory_return:
    _target_: tgdp.models.guidance.MonteCarloReturnGuide
    train_noise_conditional_network: True
    network: 
      _target_: tgdp.networks.ema_wrapper.EMANetworkWrapper
      wrapped_network:
        _target_: tgdp.networks.guides.TemporalHalfUNetFilm
        input_size: ${add:${observation_dim},${action_dim}}
        sigma_embedding:
          _target_: tgdp.networks.embeddings.SinusoidalEmbedding
          embedding_size: 32
          hidden_size_factor: 4
        local_condition_size:
        down_sizes: [32, 64, 128, 256] 
        kernel_size: 5
        fully_connected_size: 32
        n_groups: 8
        downsample: True
        predict_scale_of_condition: False
    loss_fn:
      _target_: tgdp.models.losses.ValueL2

policy:
  _target_: tgdp.models.policy.SelectActionPolicy
  action_dim: ${action_dim}

sampler:
  _target_: tgdp.sampling.DDPMSampler

noise_scheduler:
  _target_: tgdp.sampling.noise_schedulers.CosineBetaNoiseScheduler
  M: 20

sigma_distribution:
  _target_: tgdp.sigma_distributions.RandDiscreteCosineBeta
  M: 20

planner:
  _target_: tgdp.models.planning.DiffusionPlanner
  diffusion_model: ${diffusion_model}
  sampler: ${sampler}
  noise_scheduler: ${noise_scheduler}
  sigma_distribution: ${sigma_distribution}
  horizon: ${horizon}
  diffusion_steps: 20 
  action_dim: ${action_dim}
  observation_dim: ${observation_dim}
  plan_actions: True
  plan_observations: True
  observation_conditioning: True
  ensemble_num_samples: 64
  ensemble_reduction: max
  ensemble_value_key: trajectory_return

agent:
  _target_: tgdp.agent.FlatAgent
  planner: ${planner}
  policy: ${policy}
  action_dim: ${action_dim}
  observation_dim: ${observation_dim}
  replan_frequency: 1
  optimizer:
    _target_: torch.optim.Adam
    _partial_: True
    lr: 2e-4  # Paper uses 4e-5, Repo uses 2e-4

trainer:
  _target_: tgdp.training.Trainer
  train_batch_size: 64 # Paper uses batch size of 32 and accumulate_grad of 2. This is equivalent to batch size of 64 and accumulate_grad of 1.
  n_train_epochs: 100
  accumulate_grad_batches: 1
  n_train_steps_per_epoch: 10000
  ema_decay: 0.9999 # Paper uses 0.9999, Repo uses 0.995 (maybe the difference is due to the different update interval (1 vs 10))
  step_start_ema: 1000
  update_ema_every: 1
  n_test_episodes: 64
  test_every_n_epochs: 20 
  start_test_step: 100000
  load_ckpt: False
  resume_training: False
  load_ckpt_folder: 
  load_ckpt_step: 
    planner.diffusion.network: 1000000
    planner.diffusion.guides: 200000
  save_freq: 10000
  label_freq: 200000
  lightning_logger:
    _target_: lightning.pytorch.loggers.TensorBoardLogger